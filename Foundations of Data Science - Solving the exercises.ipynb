{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Data Science - Solving the exercises\n",
    "\n",
    "This notebook is an experiment with two purposes:\n",
    "\n",
    "  * Analyze if jupyter + GitHub is a viable blogging platform.\n",
    "  * Learn more about data science.\n",
    "  \n",
    "My idea is to do detailed solutions of each exercise, using the embedded Python to create plots and do numerical solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1\n",
    "\n",
    "The first two items ask to compute the expected values $E(x)$, $E(x^2)$, $E(x - y)$, $E(xy)$ and $E(x - y)^2$ for two cases:\n",
    "\n",
    "  * When $x$ and $y$ are uniform variables in the interval $[0, 1]$.\n",
    "  * When $x$ and $y$ are uniform variables in the interval $[-\\frac{1}{2}, \\frac{1}{2}]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item 2.1.1\n",
    "\n",
    "By symmetry we know that\n",
    "\n",
    "$E(x) = \\frac{1}{2}$ and\n",
    "\n",
    "$E(x - y) = 0$.\n",
    "\n",
    "Computing directly the other expressions:\n",
    "\n",
    "$E(x^2) = \\int_0^1 dx\\,x^2 = \\left.\\frac{x^3}{3}\\right|_0^1 = \\frac{1}{3}$\n",
    "\n",
    "$E(xy) = \\int_0^1 dx \\int_0^1 dy\\,xy = \\int_0^1 dx\\,x \\int_0^1 dy\\,y = \\left(\\int_0^1 dx\\,x\\right)^2 = \\left(\\left. \\frac{x^2}{2}\\right|_0^1\\right)^2 = \\left(\\frac{1}{2}\\right)^2 = \\frac{1}{4}$\n",
    "\n",
    "$E(x - y)^2 = E(x^2 - 2xy + y^2) = E(x^2) - 2E(xy) + E(y^2) = \\frac{1}{3} - 2\\cdot\\frac{1}{4} + \\frac{1}{3} = \\frac{1}{6}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using numpy to quickly check the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "from scipy import stats\n",
    "np.random.seed(12345678)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = stats.uniform.rvs(loc=0.0, scale=1.0, size=10000)\n",
    "y = stats.uniform.rvs(loc=0.0, scale=1.0, size=10000)\n",
    "print 'E(x) ~=', np.average(x)\n",
    "print 'E(x^2) ~=', np.average(x ** 2)\n",
    "print 'E(x - y) ~=', np.average(x - y)\n",
    "print 'E(xy) ~=', np.average(x * y)\n",
    "print 'E(x - y)^2 ~=', np.average((x - y) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Item 2.1.2\n",
    "\n",
    "Now by symmetry we know that\n",
    "\n",
    "$E(x) = 0$,\n",
    "\n",
    "$E(x - y) = 0$ and\n",
    "\n",
    "$E(xy) = 0$.\n",
    "\n",
    "By translational invariance,\n",
    "\n",
    "$E(x - y)^2 = \\frac{1}{6}$ like in the previous item.\n",
    "\n",
    "We can compute the variance directly,\n",
    "\n",
    "$E(x^2) = \\int_{-\\frac{1}{2}}^{\\frac{1}{2}} dx\\,x^2 = 2\\int_0^{\\frac{1}{2}} dx\\,x^2 = 2\\left.\\frac{x^3}{3}\\right|_0^{\\frac{1}{2}} = 2\\frac{\\frac{1}{8}}{3} = \\frac{1}{12}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = stats.uniform.rvs(loc=-0.5, scale=1.0, size=10000)\n",
    "y = stats.uniform.rvs(loc=-0.5, scale=1.0, size=10000)\n",
    "print 'E(x) ~=', np.average(x)\n",
    "print 'E(x^2) ~=', np.average(x ** 2)\n",
    "print 'E(x - y) ~=', np.average(x - y)\n",
    "print 'E(xy) ~=', np.average(x * y)\n",
    "print 'E(x - y)^2 ~=', np.average((x - y) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item 2.1.3\n",
    "\n",
    "As every coordinate of each point will be independent, the result will be given by multiplying the value of $E(x - y)^2$ by $d$,\n",
    "\n",
    "$E(\\mathrm{dist}) = \\frac{d}{6}$.\n",
    "\n",
    "Checking for $d = 24$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def point_rv(d):\n",
    "    return stats.uniform.rvs(loc=-0.5, scale=1.0, size=d)\n",
    "def dist_rv(d): \n",
    "    return np.sum((point_rv(d) - point_rv(d)) ** 2)\n",
    "print 'E(dist) ~=', np.average([dist_rv(24) for _ in range(10000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2\n",
    "\n",
    "We start by getting the points,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "points = np.vstack(point_rv(100) for _ in range(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then use the pairwise distance function from SciPy to calculate the distances and angles: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist\n",
    "distances = pdist(points, 'euclidean')\n",
    "angles = np.arccos(1 - pdist(points, 'cosine'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we only have to plot the resulting values,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot(distances, angles, '.'); xlabel('distances'); ylabel('angles');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and it is clear that the vectors are almost orthogonal (angles around $\\pi/2$) and with distances clustered around a single value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3\n",
    "\n",
    "We can trivially solve both items by using a nonnegative \"random variable\" $x$ such that $P(x = 0) = 1$. Then, of course, $E(x) = 0$ and $P(x \\ge a) = E(x) / a = 0$ for all positive $a$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.4\n",
    "\n",
    "If we take a random variable $x$ such that $P(x = -1) = P(x = +1) = \\frac{1}{2}$, then we clearly have $Var(x) = E(x^2) - E(x)^2 = 1 - 0 = 1$ and, if we choose $c = 1$, we get\n",
    "\n",
    "$P(|x - E(x)| \\ge 1) = P(|x| \\ge 1) = 1 = \\frac{1}{1^2} = \\frac{Var(x)}{c^2}$.\n",
    "\n",
    "To get a non-tight bound, it's as easy as using $c = 2$:\n",
    "\n",
    "$P(|x - E(x)| \\ge 1) = P(|x| \\ge 1) = 0 \\lt \\frac{1}{2^2} = \\frac{Var(x)}{c^2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.5\n",
    "\n",
    "#### Item 2.5.1\n",
    "\n",
    "We just have to impose normalization:\n",
    "\n",
    "$\\int_{-\\infty}^\\infty dx\\,p(x) = 1$\n",
    "\n",
    "$\\int_1^\\infty dx \\frac{c}{x^4} = 1$\n",
    "\n",
    "$\\left. -\\frac{c}{4 x^3} \\right|_1^\\infty = 1$\n",
    "\n",
    "$\\frac{c}{1^3} = 4$\n",
    "\n",
    "$c = 4$\n",
    "\n",
    "#### Item 2.5.2 \n",
    "\n",
    "Calculating the expected value:\n",
    "\n",
    "$\\int_{-\\infty}^\\infty dx\\,x p(x) = \\int_1^\\infty \\frac{dx\\,4}{x^3} = \\left. -\\frac{4}{3 x^2} \\right|_1^\\infty = \\frac{4}{3}$\n",
    "\n",
    "Simulating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'E(x) ~=', np.average(stats.pareto.rvs(b=3, size=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 100 samples we expect a fractional deviation around 0.1, so the result is consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.6\n",
    "\n",
    "We can just apply the definitions:\n",
    "\n",
    "$E(\\|\\mathbf{x}\\|^2) = E(\\sum_{i=1}^d x_i^2) = \\sum_{i=1}^d E(x_i^2) = \\sum_{i=1}^d \\frac{1}{2} = \\frac{d}{2}$\n",
    "\n",
    "Checking for $d = 50$,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sph_normal_point_rv(d, sigma):\n",
    "    return stats.norm.rvs(loc=0.0, scale=np.sqrt(sigma), size=d)\n",
    "points = np.vstack(sph_normal_point_rv(50, 0.5) for _ in range(1000))\n",
    "sq_dists = np.sum(points ** 2, axis=-1)\n",
    "print 'E(||x||^2) ~=', np.average(sq_dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it clearly matches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
